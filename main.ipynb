{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c8d5485-1510-431e-b47b-50077280a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt \n",
    "from numpy.fft import fft2, ifft2, fftshift, ifftshift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f19ce-e008-47bc-b768-4089537adcf2",
   "metadata": {},
   "source": [
    "The following sub-routine is for displaying the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89c6595-327b-4634-941a-ab1c8626e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image,title):\n",
    "    plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee42c3-d53c-42a6-88da-970a8daca211",
   "metadata": {},
   "source": [
    "The following sub-routine is for computing the structural similarity index between two images\n",
    "The value range is between 0 to 1\n",
    "where 1 : Perfectly similar \n",
    "where 0: completely different\n",
    "\n",
    "So, a high SSIM score indicate that the images are very very similar and a low score would indicate that some alterations have been done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "230132bb-9973-4ab1-9c66-0e4dfb6815b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ssim(image1, image2):\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    score, diff = ssim(gray1, gray2, full=True)\n",
    "    print(f\"SSIM Score: {score}\")\n",
    "    \n",
    "    plt.imshow(diff, cmap='gray')\n",
    "    plt.title('SSIM Difference')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed095f6-bddc-4a2b-8bb3-9a8f1fc8a515",
   "metadata": {},
   "source": [
    "The following sub-routine is for finding the Fast Fourier Transformation Magnitude Spectrum Difference where \n",
    "0: no difference in the frequencyy domain\n",
    "Higher Values: some changes or significant changes in frequency components\n",
    "\n",
    "The reason for checking this is to find whether some changes have been made to the image, say\n",
    "1. smoothing\n",
    "2. filtering\n",
    "3. sharpening\n",
    "4. some geometric transformation\n",
    "5. corruption, erosion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b66451-921e-4844-bb6c-00be6548b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_analysis(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    f = fft2(gray)\n",
    "    fshift = fftshift(f)\n",
    "    magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "    \n",
    "    plt.imshow(magnitude_spectrum, cmap='gray')\n",
    "    plt.title('FFT Magnitude Spectrum')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Max magnitude in FFT:\", np.max(magnitude_spectrum))\n",
    "    print(\"Mean magnitude in FFT:\", np.mean(magnitude_spectrum))\n",
    "    \n",
    "    return fshift, magnitude_spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0669cbbc-10e3-4c25-bfab-02b0441edc11",
   "metadata": {},
   "source": [
    "The following sub-routine is for edge detection where we identify the boundaries in an image which could tell us whether an image has undergone smoothing or sharpening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7436afd4-ebf7-47a2-ac58-e26a8bcc64da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_detection(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    \n",
    "    plt.imshow(edges, cmap='gray')\n",
    "    plt.title('Edge Detection')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90189c58-771d-4bcd-8056-666952398e77",
   "metadata": {},
   "source": [
    "The following sub-routine is for checking whether there are any geometric transformations where \n",
    "less number of keypoints would suggest that the image has undergone geometric transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c0e51b1-c947-4b1a-9e4d-18265f3e16c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_transformations(image1, image2):\n",
    "    orb = cv2.ORB_create()\n",
    "    kp1, des1 = orb.detectAndCompute(image1, None)\n",
    "    kp2, des2 = orb.detectAndCompute(image2, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    \n",
    "    img_matches = cv2.drawMatches(image1, kp1, image2, kp2, matches[:10], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    display_image(img_matches, 'Keypoint Matches (for Geometric Transformation Detection)')\n",
    "    \n",
    "    print(f\"Number of Matches: {len(matches)}\")\n",
    "    print(f\"Mean Match Distance: {np.mean([m.distance for m in matches])}\")\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b449091-0a26-41e5-ba6f-428491bde38d",
   "metadata": {},
   "source": [
    "The following sub-routine will perform all the above sub-routines and then show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b11c81e6-115a-4869-93f0-42cd947226b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_transformations_and_changes(original_image, suspected_image):\n",
    "    print(\"--- Original Image ---\")\n",
    "    display_image(original_image, \"Original Image\")\n",
    "    \n",
    "    print(\"--- Suspected Image ---\")\n",
    "    display_image(suspected_image, \"Suspected Image\")\n",
    "    \n",
    "    print(\"--- SSIM Structural Similarity ---\")\n",
    "    ssim_score = compute_ssim(original_image, suspected_image)\n",
    "    \n",
    "    print(\"--- FFT Analysis ---\")\n",
    "    fft_orig, fft_orig_mag = fft_analysis(original_image)\n",
    "    fft_suspected, fft_suspected_mag = fft_analysis(suspected_image)\n",
    "    \n",
    "    fft_diff = np.mean(np.abs(fft_orig_mag - fft_suspected_mag))\n",
    "    print(f\"Mean FFT Magnitude Difference: {fft_diff}\")\n",
    "    \n",
    "    print(\"--- Edge Detection ---\")\n",
    "    edge_orig = edge_detection(original_image)\n",
    "    edge_suspected = edge_detection(suspected_image)\n",
    "    \n",
    "    edge_diff = edge_difference(edge_orig, edge_suspected)\n",
    "    \n",
    "    print(\"--- Detecting Geometric Transformations ---\")\n",
    "    matches = detect_transformations(original_image, suspected_image)\n",
    "    \n",
    "    return {\n",
    "        \"ssim_score\": ssim_score,\n",
    "        \"fft_diff\": fft_diff,\n",
    "        \"edge_diff\": edge_diff,\n",
    "        \"geometric_matches\": len(matches)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7930921-9dcf-4eff-b0f0-a2280019a749",
   "metadata": {},
   "source": [
    "The following sub-routine will perform a routine where it will check whether a given image is real or some plagiarised image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b20be28-aeee-49ac-8f47-aa2908faf347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_real(ssim_score, fft_diff, edge_diff, geometric_matches):\n",
    "    SSIM_THRESHOLD = 0.85        \n",
    "    FFT_DIFF_THRESHOLD = 20.0    \n",
    "    EDGE_DIFF_THRESHOLD = 10.0   \n",
    "    GEOMETRIC_MATCH_THRESHOLD = 15  \n",
    "    \n",
    "    if ssim_score < SSIM_THRESHOLD:\n",
    "        print(\"Conclusion: Image is likely plagiarized due to low structural similarity (SSIM).\")\n",
    "        return \"Plagiarized\"\n",
    "    \n",
    "    if fft_diff > FFT_DIFF_THRESHOLD:\n",
    "        print(\"Conclusion: Image has undergone frequency modifications (blurring, filtering, sharpening).\")\n",
    "        return \"Plagiarized\"\n",
    "    \n",
    "    if edge_diff > EDGE_DIFF_THRESHOLD:\n",
    "        print(\"Conclusion: Image has been sharpened or smoothed.\")\n",
    "        return \"Plagiarized\"\n",
    "    \n",
    "    if geometric_matches < GEOMETRIC_MATCH_THRESHOLD:\n",
    "        print(\"Conclusion: Image has undergone geometric transformations (rotation, scaling, etc.).\")\n",
    "        return \"Plagiarized\"\n",
    "    \n",
    "    print(\"Conclusion: Image is likely real (not significantly altered).\")\n",
    "    return \"Real\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274da9bc-59a7-4dd3-a627-b295b3fbad5f",
   "metadata": {},
   "source": [
    "actual main code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9da982c-514d-42bf-8499-9621ba84506f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original Image ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1797.484] global loadsave.cpp:241 findDecoder imread_('./fake-vangogh-starry.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@1797.484] global loadsave.cpp:241 findDecoder imread_('./fake-vangogh-starry.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/runner/miniforge3/conda-bld/libopencv_1721305877408/work/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m original_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./fake-vangogh-starry.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      3\u001b[0m suspected_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./fake-vangogh-starry.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m detect_transformations_and_changes(original_image, suspected_image)\n\u001b[1;32m      6\u001b[0m final_decision \u001b[38;5;241m=\u001b[39m is_image_real(\n\u001b[1;32m      7\u001b[0m     ssim_score\u001b[38;5;241m=\u001b[39mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mssim_score\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      8\u001b[0m     fft_diff\u001b[38;5;241m=\u001b[39mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfft_diff\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      9\u001b[0m     edge_diff\u001b[38;5;241m=\u001b[39mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_diff\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     10\u001b[0m     geometric_matches\u001b[38;5;241m=\u001b[39mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometric_matches\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Decision: The image is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_decision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m, in \u001b[0;36mdetect_transformations_and_changes\u001b[0;34m(original_image, suspected_image)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_transformations_and_changes\u001b[39m(original_image, suspected_image):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Original Image ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     display_image(original_image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Image\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Suspected Image ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     display_image(suspected_image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuspected Image\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m, in \u001b[0;36mdisplay_image\u001b[0;34m(image, title)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdisplay_image\u001b[39m(image,title):\n\u001b[0;32m----> 2\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mcvtColor(image,cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n\u001b[1;32m      3\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(title)\n\u001b[1;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /Users/runner/miniforge3/conda-bld/libopencv_1721305877408/work/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    original_image = cv2.imread('./fake-vangogh-starry.jpg') \n",
    "    suspected_image = cv2.imread('./fake-vangogh-starry.jpg') \n",
    "    results = detect_transformations_and_changes(original_image, suspected_image)\n",
    "    \n",
    "    final_decision = is_image_real(\n",
    "        ssim_score=results['ssim_score'], \n",
    "        fft_diff=results['fft_diff'], \n",
    "        edge_diff=results['edge_diff'], \n",
    "        geometric_matches=results['geometric_matches']\n",
    "    )\n",
    "\n",
    "    print(f\"Final Decision: The image is {final_decision}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3b086-4efc-4b9b-8174-99b24a56e123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
